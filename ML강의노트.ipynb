{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML강의노트.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMY307Tv7BX/rptxxZb4s0A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wuIfwpO-rYS6","executionInfo":{"status":"ok","timestamp":1624284531771,"user_tz":-540,"elapsed":228,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"4e9d3e05-8b4e-44b5-b52c-c2eea54d1a17"},"source":["import tensorflow as tf\n","hello = tf.constant(\"Hello, TensorFLow!\")\n","print(hello)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf.Tensor(b'Hello, TensorFLow!', shape=(), dtype=string)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kzx-yoXy5wmf"},"source":["node1 = tf.constant(3.0, tf.float32)\n","node2 = tf.constant(4.0, tf.float32)\n","node3 = tf.add(node1, node2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i20bQZ7e59rm","executionInfo":{"status":"ok","timestamp":1624284599267,"user_tz":-540,"elapsed":218,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"1ec835ec-a949-4196-a7a8-108ae8bf5c9c"},"source":["print(node1, node2, node3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(4.0, shape=(), dtype=float32) tf.Tensor(7.0, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSAxEErR6A--","executionInfo":{"status":"ok","timestamp":1624284662479,"user_tz":-540,"elapsed":219,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"cf0ef5a6-5779-4a91-c1bd-bf79a2f0ef6a"},"source":["print(node1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf.Tensor(3.0, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uv4Nwf6b6QcY","executionInfo":{"status":"ok","timestamp":1624284711017,"user_tz":-540,"elapsed":205,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"eb89bf7f-fc1d-4a01-bf4b-771d7386f052"},"source":["tf.print(node1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fo6O0Eue6cZL","executionInfo":{"status":"ok","timestamp":1624284753903,"user_tz":-540,"elapsed":218,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"2334defc-bd41-4c45-9968-7d2cfaa9adb5"},"source":["tf.print(node1, node2, node3, tf.float32)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3 4 7 tf.float32\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SCa8WBcl47EX"},"source":["x = [1,2,3,4,5]\n","y = [1,2,3,4,5]\n","W = tf.Variable(2.9)#임의의 값이다. 랜덤값 입력해도 좋다\n","b = tf.Variable(0.5)\n","\n","hypothesis = W*x + b\n","cost = tf.reduce_mean(tf.square(hypothesis - y))\n","#tf.reduce_mean(v)=> 차원이 하나 줄면서 평균을 구한다\n","#tf.square(3) => 9\n","\n","#Gradient descent: 경사를 하강하면서 minimize cost를 찾는 방법이다\n","learning_rate = 0.01#기울기를 얼마나 반영할건지\n","\n","for i in range(100):\n","  with tf.GradientTape() as tape:\n","  hypothesis = W*x + b\n","  cost = tf.reduce_mean(tf.square(hypothesis - y))\n","\n","  W_grad, b_grad = tape.gradient(cost, [W,b])\n","  W.assign_sub(learning_rate*W_grad)\n","  b.assign_sub(learning_rate*b_grad)\n","  if i%10 == 0:\n","    print(\"{:5}|{:10.4f}|{:10.6f}\".format(i, W.numpy(), b.numpy(), cost))\n","\n","#A.assign_sub(B): A = A - B "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"0_ABIf1Q7bae","executionInfo":{"status":"ok","timestamp":1624368905730,"user_tz":-540,"elapsed":244,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"c3e43305-e418-425f-cd2b-d1d28a6f4aa9"},"source":["#lab03-1\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","#tf.enable_eager_execution()\n","tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.5.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWmjJiBb7nuf","executionInfo":{"status":"ok","timestamp":1624369197965,"user_tz":-540,"elapsed":255,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"d03cac64-a414-4783-c7f3-49a133d70649"},"source":["#lab03-1\n","\n","import numpy as np\n","\n","X = np.array([1,2,3])\n","Y = np.array([1,2,3])\n","\n","def cost_func(W, X, Y):\n","  c = 0\n","  for i in range(len(X)):\n","    c += (W*X[i]-Y[i])**2\n","  return c/len(X)\n","\n","for x in np.linspace(-3, 5, num=15):\n","  curr_cost= cost_func(x, X, Y)\n","  print(\"{:6.3f} | {:10.5f}\".format(x, curr_cost))\n","  \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-3.000 |   74.66667\n","-2.429 |   54.85714\n","-1.857 |   38.09524\n","-1.286 |   24.38095\n","-0.714 |   13.71429\n","-0.143 |    6.09524\n"," 0.429 |    1.52381\n"," 1.000 |    0.00000\n"," 1.571 |    1.52381\n"," 2.143 |    6.09524\n"," 2.714 |   13.71429\n"," 3.286 |   24.38095\n"," 3.857 |   38.09524\n"," 4.429 |   54.85714\n"," 5.000 |   74.66667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11EBgzdA8vEz","executionInfo":{"status":"ok","timestamp":1624369590428,"user_tz":-540,"elapsed":1063,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"a0bd8b87-0b48-4316-b777-d26d1ec88296"},"source":["#lab03-1\n","\n","tf.random.set_seed(0)\n","X = [1. , 2., 3., 4.]\n","Y = [1., 3., 5., 7.]\n","\n","W = tf.Variable(tf.random.normal([1], -100., 100.))\n","for step in range(300):\n","  hypothesis = W*X\n","  cost = tf.reduce_mean(tf.square(hypothesis - Y))\n","\n","  alpha = 0.01\n","  gradient = tf.reduce_mean(tf.multiply(tf.multiply(W,X) - Y,X))\n","  descent = W - tf.multiply(alpha, gradient)\n","  W.assign(descent)\n","\n","  if step%10 == 0:\n","    print('{:5} | {:10.4f} | {:10.6f}'.format(step, cost.numpy(), W.numpy()[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["    0 | 18332.2188 |  47.398293\n","   10 |  3855.3564 |  22.638384\n","   20 |   810.9046 |  11.283927\n","   30 |   170.6631 |   6.076973\n","   40 |    36.0217 |   3.689155\n","   50 |     7.7069 |   2.594144\n","   60 |     1.7524 |   2.091991\n","   70 |     0.5001 |   1.861713\n","   80 |     0.2368 |   1.756112\n","   90 |     0.1814 |   1.707684\n","  100 |     0.1698 |   1.685477\n","  110 |     0.1673 |   1.675292\n","  120 |     0.1668 |   1.670622\n","  130 |     0.1667 |   1.668481\n","  140 |     0.1667 |   1.667498\n","  150 |     0.1667 |   1.667048\n","  160 |     0.1667 |   1.666842\n","  170 |     0.1667 |   1.666747\n","  180 |     0.1667 |   1.666703\n","  190 |     0.1667 |   1.666684\n","  200 |     0.1667 |   1.666674\n","  210 |     0.1667 |   1.666670\n","  220 |     0.1667 |   1.666668\n","  230 |     0.1667 |   1.666667\n","  240 |     0.1667 |   1.666667\n","  250 |     0.1667 |   1.666667\n","  260 |     0.1667 |   1.666667\n","  270 |     0.1667 |   1.666667\n","  280 |     0.1667 |   1.666667\n","  290 |     0.1667 |   1.666667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGugELI1-OqP","executionInfo":{"status":"ok","timestamp":1624372342484,"user_tz":-540,"elapsed":3561,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"d1e71ee7-be97-4665-c3d0-94f4a31948c1"},"source":["#lab04-1\n","#tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)\n","# 균등분포로부터의 난수값을 반환합니다. 생성된 값들은 [minval, maxval]구간의 균등분포를 따릅니다. 하한 minval은 구간에 포함(included)되는 반면, 상한인 maxval은 포함되지 않습니다(excluded).\n","#https://rfriend.tistory.com/m/556?category=711317\n","import tensorflow as tf\n","x_data = [\n","          [1., 1., 1., 1., 1.],\n","          [1., 0., 3., 0., 5.],\n","          [0., 0., 0., 4., 0.]\n","]\n","\n","y_data = [1,2,3,4,5]\n","\n","W = tf.Variable(tf.random.uniform([1,3], -1.0, 1.0))\n","learning_rate = 0.001\n","optimizer = tf.optimizers.SGD(learning_rate)\n","\n","for i in range(1000+1):\n","  with tf.GradientTape() as tape:\n","    hypothesis = tf.matmul(W, x_data)\n","    cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n","  \n","    grads = tape.gradient(cost, [W])\n","    optimizer.apply_gradients(grads_and_vars=zip(grads,[W]))\n","    if i%50 == 0:\n","      print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.4f}\".format(i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], W.numpy()[0][2]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["    0 |  18.524368 |    -0.6423 |    -0.3426 |     0.7140\n","   50 |   4.869568 |    -0.3670 |     0.3987 |     0.8259\n","  100 |   1.794136 |    -0.2132 |     0.7388 |     0.8930\n","  150 |   1.070846 |    -0.1183 |     0.8914 |     0.9334\n","  200 |   0.877597 |    -0.0527 |     0.9569 |     0.9574\n","  250 |   0.807805 |    -0.0020 |     0.9818 |     0.9708\n","  300 |   0.769189 |     0.0406 |     0.9882 |     0.9774\n","  350 |   0.740003 |     0.0786 |     0.9861 |     0.9795\n","  400 |   0.714705 |     0.1137 |     0.9804 |     0.9785\n","  450 |   0.691662 |     0.1467 |     0.9732 |     0.9754\n","  500 |   0.670282 |     0.1781 |     0.9654 |     0.9710\n","  550 |   0.650285 |     0.2082 |     0.9576 |     0.9656\n","  600 |   0.631515 |     0.2373 |     0.9499 |     0.9597\n","  650 |   0.613861 |     0.2653 |     0.9424 |     0.9535\n","  700 |   0.597243 |     0.2924 |     0.9351 |     0.9471\n","  750 |   0.581589 |     0.3187 |     0.9280 |     0.9406\n","  800 |   0.566842 |     0.3442 |     0.9211 |     0.9341\n","  850 |   0.552946 |     0.3688 |     0.9145 |     0.9277\n","  900 |   0.539850 |     0.3928 |     0.9081 |     0.9214\n","  950 |   0.527509 |     0.4160 |     0.9018 |     0.9152\n"," 1000 |   0.515879 |     0.4385 |     0.8958 |     0.9091\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MLWPgwak7hvJ","colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"status":"error","timestamp":1624456207419,"user_tz":-540,"elapsed":363,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12807627233737898215"}},"outputId":"01694df2-5f75-4ea8-b9c4-0402a16fc65f"},"source":["#lab05\n","import tensorflow as tf\n","\n","x_train = [[1., 2.],\n","           [2., 3.],\n","           [3., 1.],\n","           [4., 3.],\n","           [5., 3.],\n","           [6., 2.]]\n","y_train = [[0.],\n","           [0.],\n","           [0.],\n","           [1.],\n","           [1.],\n","           [1.]]\n","x_test = [[5., 2.]]\n","y_test = [[1.]]\n","\n","#import tensorflow.contrib.eager as tfe\n","#tf.enable_eager_execution()\n","dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n","W = tf.Variable(tf.zeros([2,1]), name='weight')\n","b = tf.Variable(tf.zeros([1]), name = 'bias')\n","\n","def logistic_regression(features):\n","  hypothesis = tf.div(1., 1.+tf.exp(tf.matmul(features, W) + b))\n","  return hypothesis\n","\n","def loss_fn(hypothesis, featues, labels):\n","  cost = -tf.reduce_mean(labels, * tf.log(loss_fn(hypothesis) + (1-labels)*tf.log(1-hypothesis)))\n","  return cost\n","\n","def grad(hypothesis, features, labels):\n","  with tf.GradientTape() as tape:\n","    loss_value = loss_fn(hypothesis, labels)\n","  return tape.gradient(loss_value, [W,b])\n","\n","optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01)\n","for step in range(1000):\n","  for features, labels in tf.data.Iterator(dataset):\n","    grads = grad(logistic_regression(features), features, labels)\n","    optimizer.apply_gradients(grads_and_vars=zip(grads, [W,b]))\n","    if step%100 ==0:\n","      print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features), labels)))\n","\n","def accuracy_fn(hypothesis, labels):\n","  predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n","  accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=float32))\n","  return accuracy\n","test_acc = accuracy_fn(logistic_regression(x_test), y_test)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-66e672bb4252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: IteratorBase() takes no arguments"]}]},{"cell_type":"code","metadata":{"id":"I5uSDVcsHk1J"},"source":["import tensorflow as tf\n","import numpy as np\n","\n","print(tf.__version__)\n","\n","tf.random.set_seed(777)  # for reproducibility\n","\n","xy = np.loadtxt('data-04-zoo.csv', delimiter=',', dtype=np.float32)\n","x_data = xy[:, 0:-1]\n","y_data = xy[:, -1]\n","\n","nb_classes = 7  # 0 ~ 6\n","\n","# Make Y data as onehot shape\n","Y_one_hot = tf.one_hot(y_data.astype(np.int32), nb_classes)\n","\n","print(x_data.shape, Y_one_hot.shape)\n","\n","#Weight and bias setting\n","W = tf.Variable(tf.random.normal((16, nb_classes)), name='weight')\n","b = tf.Variable(tf.random.normal((nb_classes,)), name='bias')\n","variables = [W, b]\n","\n","# tf.nn.softmax computes softmax activations\n","# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n","def logit_fn(X):\n","    return tf.matmul(X, W) + b\n","\n","def hypothesis(X):\n","    return tf.nn.softmax(logit_fn(X))\n","\n","def cost_fn(X, Y):\n","    logits = logit_fn(X)\n","    cost_i = tf.keras.losses.categorical_crossentropy(y_true=Y, y_pred=logits, \n","                                                      from_logits=True)    \n","    cost = tf.reduce_mean(cost_i)    \n","    return cost\n","\n","def grad_fn(X, Y):\n","    with tf.GradientTape() as tape:\n","        loss = cost_fn(X, Y)\n","        grads = tape.gradient(loss, variables)\n","        return grads\n","    \n","def prediction(X, Y):\n","    pred = tf.argmax(hypothesis(X), 1)\n","    correct_prediction = tf.equal(pred, tf.argmax(Y, 1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","    return accuracy\n","\n","def fit(X, Y, epochs=1000, verbose=100):\n","    optimizer =  tf.keras.optimizers.SGD(learning_rate=0.1)\n","\n","    for i in range(epochs):\n","        grads = grad_fn(X, Y)\n","        optimizer.apply_gradients(zip(grads, variables))\n","        if (i==0) | ((i+1)%verbose==0):\n","#             print('Loss at epoch %d: %f' %(i+1, cost_fn(X, Y).numpy()))\n","            acc = prediction(X, Y).numpy()\n","            loss = cost_fn(X, Y).numpy() \n","            print('Steps: {} Loss: {}, Acc: {}'.format(i+1, loss, acc))\n","\n","fit(x_data, Y_one_hot)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ar6w8o4PFgyW"},"source":["#lab09-1\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","tf.random.set_seed(777)\n","x_data = [[0, 0],\n","          [0,1],\n","          [1,0],\n","          [1,1]]\n","y_data = [[0],\n","          [1],\n","          [1],\n","          [0]]\n","\n","dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))\n","#tf.cast함수는 조건에 따라 0 또는 1의 값을 리턴한다\n","def preprocess_data(features, labels):\n","  features = tf.cast(features, tf.float32)\n","  labels = tf.cast(labels, tf.float32)\n","  return features, labels\n","\n","#w,b 를 선언\n","W = tf.Variable(tf.zeroes((2,1)), name = 'weight')\n","b = tf.Variable(tf.zeroes((1, )), name = 'bias')\n","\n","#sigmoid 함수를 가설로 선언\n","def logistic_regression(features):\n","  hypothesis = tf.divide(1., 1. + tf.exp(tf.matmul(features, W) + b))\n","  return hypothesis\n","\n","def loss_fn(hypothesis, features, labels):\n","  cost = -tf.reduce_mean(labels* tf.math.log(logistic_regression(features)) + (1-labels)*tf.math.log(1-hypothesis))\n","  return cost\n","\n","optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01)\n","#추론값을 0.5기준으로 0과 1의 값 리턴\n","def accuracy_fn(hypothesis, labels):\n","  predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n","  accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n","  return accuracy\n","\n","#경삿값 계산\n","#tf.gradients는 두개의 매개변수를 받습니다. \n","#첫 번째 매개변수는 편미분을 하려는 대상 텐서이고 두 번째 매개변수는 편미분 변수에 해당하는 텐서입니다.\n","def grad(hypothesis, features, labels):\n","  with tf.GradientTape as grad:\n","    loss_value = loss_fn(logistic_regression(features), features, labels)\n","  return tape.gradient(loss_value, [W,b])\n","\n","EPOCHS = 1001\n","# Apply gradients to variables. This is the second part of minimize(). \n","# It returns an Operation that applies gradients.\n","# The method sums gradients from all replicas in the presence of tf.distribute.Strategy by default. \n","# You can aggregate gradients yourself by passing experimental_aggregate_gradients=False.\n","for step in range(EPOCHS):\n","    for features, labels  in dataset:\n","        features, labels = preprocess_data(features, labels)\n","        grads = grad(logistic_regression(features), features, labels)\n","        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n","        if step % 100 == 0:\n","            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))\n","print(\"W = {}, B = {}\".format(W.numpy(), b.numpy()))\n","x_data, y_data = preprocess_data(x_data, y_data)\n","test_acc = accuracy_fn(logistic_regression(x_data),y_data)\n","print(\"Testset Accuracy: {:.4f}\".format(test_acc))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnlTaXo_jJAX"},"source":[""],"execution_count":null,"outputs":[]}]}