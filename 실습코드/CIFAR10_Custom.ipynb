{"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"colab":{"name":"CIFAR10_Custom.ipynb","provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"y5SDVClq7uwv","executionInfo":{"status":"ok","timestamp":1640005328638,"user_tz":-540,"elapsed":6,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12807627233737898215"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### CIFAR10 Dataset 생성 \n","* tf.keras.datasets의 cifar10.load_data()는 웹에서 Local computer로 Download후 train과 test용 image와 label array로 로딩. "],"metadata":{"id":"WI_b8zeb7uw3"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import cifar10\n","\n","# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","print(\"train dataset shape:\", train_images.shape, train_labels.shape)\n","print(\"test dataset shape:\", test_images.shape, test_labels.shape)"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"-_S_9HgM7uw6","executionInfo":{"status":"ok","timestamp":1640005342748,"user_tz":-540,"elapsed":10039,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12807627233737898215"}},"outputId":"9624192c-d91e-4f7d-863a-fb863ab678aa"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 3s 0us/step\n","170508288/170498071 [==============================] - 3s 0us/step\n","train dataset shape: (50000, 32, 32, 3) (50000, 1)\n","test dataset shape: (10000, 32, 32, 3) (10000, 1)\n"]}]},{"cell_type":"code","source":["train_images[0, :, :, :], train_labels[0, :]"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"YPe6zAi67uw7","executionInfo":{"status":"ok","timestamp":1640005461087,"user_tz":-540,"elapsed":272,"user":{"displayName":"‍박선우[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12807627233737898215"}},"outputId":"45ef83f3-b501-462f-bb90-6577803938c9"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[[ 59,  62,  63],\n","         [ 43,  46,  45],\n","         [ 50,  48,  43],\n","         ...,\n","         [158, 132, 108],\n","         [152, 125, 102],\n","         [148, 124, 103]],\n"," \n","        [[ 16,  20,  20],\n","         [  0,   0,   0],\n","         [ 18,   8,   0],\n","         ...,\n","         [123,  88,  55],\n","         [119,  83,  50],\n","         [122,  87,  57]],\n"," \n","        [[ 25,  24,  21],\n","         [ 16,   7,   0],\n","         [ 49,  27,   8],\n","         ...,\n","         [118,  84,  50],\n","         [120,  84,  50],\n","         [109,  73,  42]],\n"," \n","        ...,\n"," \n","        [[208, 170,  96],\n","         [201, 153,  34],\n","         [198, 161,  26],\n","         ...,\n","         [160, 133,  70],\n","         [ 56,  31,   7],\n","         [ 53,  34,  20]],\n"," \n","        [[180, 139,  96],\n","         [173, 123,  42],\n","         [186, 144,  30],\n","         ...,\n","         [184, 148,  94],\n","         [ 97,  62,  34],\n","         [ 83,  53,  34]],\n"," \n","        [[177, 144, 116],\n","         [168, 129,  94],\n","         [179, 142,  87],\n","         ...,\n","         [216, 184, 140],\n","         [151, 118,  84],\n","         [123,  92,  72]]], dtype=uint8), array([6], dtype=uint8))"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["NAMES = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n","print(train_labels[:10])"],"metadata":{"trusted":true,"id":"YS2K41uV7uw8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### CIFAR10 데이터 시각화\n","* 이미지 크기는 32x32이며 RGB채널. \n","* 전반적으로 Label에 해당하는 대상이 이미지의 중앙에 있고, Label 대상 오브젝트 위주로 이미지가 구성. "],"metadata":{"id":"DHDbMQJf7uw8"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import cv2\n","%matplotlib inline \n","\n","def show_images(images, labels, ncols=8):\n","    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)\n","    for i in range(ncols):\n","        axs[i].imshow(images[i])\n","        label = labels[i].squeeze()\n","        axs[i].set_title(NAMES[int(label)])\n","        \n","show_images(train_images[:8], train_labels[:8], ncols=8)\n","show_images(train_images[8:16], train_labels[8:16], ncols=8)"],"metadata":{"trusted":true,"id":"C9Hw564q7uw9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data preprocessing\n","* image array의 0 ~ 255 사이의 값으로 되어 있는 pixel intensity 값을 0 ~ 1 사이 값으로 변환. 정수값 pixel 값을 255.0 으로 나눔. \n","* label array는 숫자형 값으로 바꾸되, 원-핫 인코딩을 적용할지 선택. 일반적으로 원-핫 인코딩을 적용하는게 Keras Framework활용이 용이\n","* image array, label array 모두 float32 형으로 변환. numpy 의 float32는 tensor 변환시 tf.float32 로 변환되며 기본적으로 Tensorflow backend Keras는 tf.float32를 기반으로 함. \n"],"metadata":{"id":"R5iI1a237uw-"}},{"cell_type":"code","source":["(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","\n","# label은 원-핫 인코딩이 Keras에서는 활용이 용이하나, 여기서는 sparse categorical crossentropy 테스트를 위해 적용하지 않음. \n","def get_preprocessed_data(images, labels):\n","    \n","    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n","    images = np.array(images/255.0, dtype=np.float32)\n","    labels = np.array(labels, dtype=np.float32)\n","    \n","    return images, labels\n","\n","train_images, train_labels = get_preprocessed_data(train_images, train_labels)\n","test_images, test_labels = get_preprocessed_data(test_images, test_labels)"],"metadata":{"trusted":true,"id":"JoosHNVp7uw-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images[0, :, :, :]"],"metadata":{"trusted":true,"id":"Z7JaF7is7uxB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Keras는 CNN(정확히는 CNN 2D) 모델에 학습 데이터를 입력할 시 반드시 Image array는 4차원 배열이 되어야 함. \n","# RGB 채널 이미지 array는 기본적으로 3차원임. 여기에 이미지의 갯수를 포함하므로 4차원이 됨.  \n","# 만일 Grayscale인 2차원 이미지 array라도 의도적으로 채널을 명시해서 3차원으로 만들어 주고, 여기에 이미지 개수를 포함해서 4차원이 됨. \n","\n","print(train_images.shape, train_labels.shape)"],"metadata":{"trusted":true,"id":"q154rJ2b7uxC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label 데이터가 2차원임. 이를 Keras 모델에 입력해도 별 문제없이 동작하지만, label의 경우는 OHE적용이 안되었는지를 알 수 있게 명확하게 1차원으로 표현해 주는것이 좋음. \n","# 2차원인 labels 데이터를 1차원으로 변경. \n","train_labels = train_labels.squeeze()\n","test_labels = test_labels.squeeze()"],"metadata":{"trusted":true,"id":"4Qhl5Ew17uxD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Custom Model 생성\n","* CNN Model의 맨처음 Layer는 Input layer. Input layer의 shape를 이미지 사이즈와 RGB 3채널에 맞게 (32, 32, 3) 으로 설정.\n","* Conv 연산을 연달아 적용하고 MaxPooling을 적용하는 루틴으로 모델 생성. MaxPooling을 적용 후에는 필터 갯수를 더욱 증가 시킴. \n","* MaxPooling 적용 후에 출력 피처맵의 사이즈는 작아지되, 채널(깊이)는 늘어나는 형태로 모델 생성. \n","* CIFAR10의 Label수가 10개이므로 Classification을 위한 맨 마지막 Dense layer의 units 갯수는 10개임\n","* label값이 원-핫 인코딩 되지 않았기 때문에 model.compile()에서 loss는 반드시 sparse_categorical_crossentropy여야함. \n","* 만일 label값이 원-핫 인코딩 되었다면 loss는 categorical_crossentropy 임. "],"metadata":{"id":"G8nLig6Q7uxF"}},{"cell_type":"code","source":["IMAGE_SIZE = 32"],"metadata":{"trusted":true,"id":"Qg2RB_zO7uxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","\n","#x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(input_tensor)\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","x = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(x)\n","x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D(pool_size=2)(x)\n","\n","x = Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(x)\n","x = Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(x)\n","x = MaxPooling2D(pool_size=2)(x)\n","\n","# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n","x = Flatten(name='flatten')(x)\n","x = Dropout(rate=0.5)(x)\n","x = Dense(300, activation='relu', name='fc1')(x)\n","x = Dropout(rate=0.3)(x)\n","output = Dense(10, activation='softmax', name='output')(x)\n","\n","model = Model(inputs=input_tensor, outputs=output)\n","\n","model.summary()"],"metadata":{"trusted":true,"id":"f05Blior7uxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# optimizer는 Adam으로 설정하고, label값이 원-핫 인코딩이 아니므로 loss는 sparse_categorical_crossentropy 임. \n","model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"trusted":true,"id":"yQGsy9I87uxH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model 학습 수행 및 테스트 데이터로 평가 \n","* Model의 fit() 메소드를 호출하여 학습\n","* fit()은 학습 데이터가 Numpy array 자체로 들어올때, Generator 형태로 들어올때 약간의 수행로직 차이가 있음. \n","* 인자로 x에는 학습 image data, y는 학습 label 데이터. \n","* batch_size는 한번에 가져올 image/label array 갯수. 1개씩 가져오면 수행속도가 너무 느리고, 전체를 가져오면 GPU Memory 부족이 발생할 수 있으므로 적절한 batch_size 설정이 필요. 만약 학습 데이터가 generator일 경우, fit()에서 batch_size를 설정하지 않음. \n","* epochs 는 전체 학습 데이터 학습을 반복 수행할 횟수\n","* steps_per_epoch는 전체 학습 데이터를 몇번 배치 작업으로 수행하는가를 의미. 보통 입력데이터가 generator일 경우 설정. \n","* validation_data는 검증용 데이터 세트\n","* validation_steps는 검증용 데이터의 steps_per_epoch임. \n","* validation_split는 validation_data로 별도의 검증용 데이터 세트를 설정하지 않고 자동으로 학습용 데이터에서 검증용 데이터 세트 분할. \n"],"metadata":{"id":"yDo9Q29X7uxH"}},{"cell_type":"code","source":["history = model.fit(x=train_images, y=train_labels, batch_size=64, epochs=30, validation_split=0.15 )"],"metadata":{"trusted":true,"id":"hAUN1R5c7uxI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_history(history):\n","    plt.figure(figsize=(6, 6))\n","    plt.yticks(np.arange(0, 1, 0.05))\n","    plt.plot(history.history['accuracy'], label='train')\n","    plt.plot(history.history['val_accuracy'], label='valid')\n","    plt.legend()\n","    \n","show_history(history)\n","\n","# 테스트 데이터로 성능 평가\n","model.evaluate(test_images, test_labels)"],"metadata":{"trusted":true,"id":"S8Fq1Fau7uxI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### model.predict()를 통해 이미지 분류 예측\n","* 4차원 이미지 배열을 입력해서 모델학습함. predict()시에도 4차원 이미지 배열을 입력해야함. \n","* 학습 데이터의 원-핫 인코딩 적용 여부와 관계없이 softmax 적용 결과는 무조건 2차원 임에 유의  "],"metadata":{"id":"jBTP7TZO7uxI"}},{"cell_type":"code","source":["# 아래 코드는 오류 발생. Conv2D를 사용한 모델에 4차원 이미지 배열을 입력해서 모델을 학습했으므로 predict()시에도 테스트용 4차원 이미지 배열을 입력해야 함.  \n","preds = model.predict(test_images[0])"],"metadata":{"trusted":true,"id":"pAhnLQQx7uxJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트용 4차원 이미지 배열을 입력해서 predict()수행. \n","# predict()의 결과는 softmax 적용 결과임. 학습 데이터의 원-핫 인코딩 적용 여부와 관계없이 softmax 적용 결과는 무조건 2차원 임에 유의 \n","preds = model.predict(np.expand_dims(test_images[0], axis=0))\n","print('예측 결과 shape:', preds.shape)\n","print('예측 결과:', preds)"],"metadata":{"trusted":true,"id":"llqrK0sz7uxJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = model.predict(test_images[:32], batch_size=32)\n","print('예측 결과 shape:', preds.shape)\n","print('예측 결과:', preds)"],"metadata":{"trusted":true,"id":"Ogw9-pZt7uxJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_class = np.argmax(preds, axis=1)\n","print('예측 클래스 값:', predicted_class)"],"metadata":{"trusted":true,"id":"T1I45jUz7uxK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_images(test_images[:8], predicted_class[:8], ncols=8)\n","show_images(test_images[:8], test_labels[:8], ncols=8)"],"metadata":{"trusted":true,"id":"o9wvYUQC7uxK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"trusted":true,"id":"Izt2B5WT7uxK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 평균이 1 이고 표준편차가 1인 표준 정규분포에서 난수 추출\n","* 표준 편차가 클 수록 개별 값의 크기가 일반적으로 커짐."],"metadata":{"id":"jYVlgdkL7uxK"}},{"cell_type":"code","source":["numbers = np.random.normal(loc=0.0,scale=1,size=[100, 100])\n","print(numbers)\n","print(numbers.mean())\n","print(numbers.std())\n","print(numbers.sum())"],"metadata":{"trusted":true,"id":"J_xx20K47uxL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Xavier initialization - 정규분포(glorot_normal), 균일분포(glorot_uniform) "],"metadata":{"id":"vrSfO5AQ7uxL"}},{"cell_type":"code","source":["# glorot_normal\n","fan_in = 20\n","fan_out = 15\n","scale_value = np.sqrt(2/(fan_in + fan_out))\n","print('scale:', scale_value)\n","weights = np.random.normal(loc=0.0, scale=scale_value, size=(100, 100))\n","print(weights)\n","print('weights mean:',weights.mean(), 'std:', weights.std(), 'sum:', weights.sum())"],"metadata":{"trusted":true,"id":"WM-asKCA7uxL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# glorot_uniform\n","fan_in = 10\n","fan_out = 8\n","limit = np.sqrt(6/(fan_in + fan_out))\n","print('limit:', limit)\n","weights = np.random.uniform(-1*limit, limit, size=(100, 100))\n","print(weights)\n","print('weights mean:',weights.mean(), 'std:', weights.std(), 'sum:', weights.sum())"],"metadata":{"trusted":true,"id":"ZBbFfz6Z7uxM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### He initialization - 정규분포(he_normal), 균일분포(he_uniform) "],"metadata":{"id":"99bst_i97uxM"}},{"cell_type":"code","source":["fan_in = 10\n","fan_out = 8\n","scale_value = np.sqrt(2/(fan_in))\n","print('scale:', scale_value)\n","weights = np.random.normal(loc=0.0, scale=scale_value, size=(100, 100))\n","print(weights)\n","print('weights mean:',weights.mean(), 'std:', weights.std(), 'sum:', weights.sum())"],"metadata":{"trusted":true,"id":"aESxYboh7uxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fan_in = 10\n","fan_out = 8\n","limit = np.sqrt(6/(fan_in))\n","print('limit:', limit)\n","weights = np.random.uniform(-1*limit, limit, size=(100, 100))\n","print(weights)\n","print('weights mean:',weights.mean(), 'std:', weights.std(), 'sum:', weights.sum())"],"metadata":{"trusted":true,"id":"7ld_WZce7uxM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### weight 초기화를 He Normal로 변경 후 성능 검증\n","* Keras Conv2D의 기본 weight 초기화는 glorot_uniform임. 이를 he_normal로 변경 후 동일 모델로 성능 테스트 \n","* label은 원-핫 인코딩을 적용 "],"metadata":{"id":"rgEDqbpP7uxN"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","def get_preprocessed_data(images, labels):\n","    \n","    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n","    images = np.array(images/255.0, dtype=np.float32)\n","    labels = np.array(labels, dtype=np.float32)\n","    labels = labels.squeeze()\n","    \n","    return images, labels\n","\n","# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n","def get_preprocessed_ohe(images, labels):\n","    images, labels = get_preprocessed_data(images, labels)\n","    # OHE 적용 \n","    oh_labels = to_categorical(labels)\n","    return images, oh_labels\n","\n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","\n","train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n","test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n","print(train_images.shape, train_oh_labels.shape, test_images.shape, test_oh_labels.shape)"],"metadata":{"trusted":true,"id":"2gcjOGyS7uxN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","\n","#x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer='he_normal')(input_tensor)\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer='he_normal')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","x = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n","x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D(pool_size=2)(x)\n","\n","x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n","x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\n","x = MaxPooling2D(pool_size=2)(x)\n","\n","# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n","x = Flatten(name='flatten')(x)\n","x = Dropout(rate=0.5)(x)\n","x = Dense(300, activation='relu', name='fc1')(x)\n","x = Dropout(rate=0.3)(x)\n","output = Dense(10, activation='softmax', name='output')(x)\n","\n","model = Model(inputs=input_tensor, outputs=output)\n","\n","model.summary()"],"metadata":{"trusted":true,"id":"CXnErr147uxN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# optimizer는 Adam으로 설정하고, label값이 원-핫 인코딩이므로 loss는 categorical_crossentropy 임. \n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","history = model.fit(x=train_images, y=train_oh_labels, batch_size=64, epochs=30, validation_split=0.15 )"],"metadata":{"trusted":true,"id":"Xkq6cEhq7uxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_history(history)\n","\n","# 테스트 데이터로 성능 평가\n","model.evaluate(test_images, test_oh_labels)"],"metadata":{"trusted":true,"id":"Mk2ZbB7t7uxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"trusted":true,"id":"_RhdZZdk7uxP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Batch Normalization을 모델에 적용 후 성능 검증"],"metadata":{"id":"BbqqDJyz7uxP"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import random as python_random\n","\n","np.random.seed(2021)\n","python_random.seed(2021)\n","tf.random.set_seed(2021)"],"metadata":{"trusted":true,"id":"oHBoSK8R7uxP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","\n","#x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(input_tensor)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","\n","x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n","x = Activation('relu')(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D(pool_size=2)(x)\n","\n","x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","\n","x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D(pool_size=2)(x)\n","\n","# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n","x = Flatten(name='flatten')(x)\n","x = Dropout(rate=0.5)(x)\n","x = Dense(300, activation='relu', name='fc1')(x)\n","x = Dropout(rate=0.3)(x)\n","output = Dense(10, activation='softmax', name='output')(x)\n","\n","model = Model(inputs=input_tensor, outputs=output)\n","\n","model.summary()"],"metadata":{"trusted":true,"id":"BV6qlhcF7uxR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label값이 원-핫 인코딩이 아니므로 loss는 categorical_crossentropy 임. \n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","history = model.fit(x=train_images, y=train_oh_labels, batch_size=64, epochs=30, validation_split=0.15)"],"metadata":{"trusted":true,"id":"tqzQfOLx7uxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.evaluate(test_images, test_oh_labels)"],"metadata":{"trusted":true,"id":"DxitGboD7uxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"trusted":true,"id":"lKPY2Cz-7uxT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### He Normal 적용 후 Batch Normalization"],"metadata":{"id":"Wu0HlqKZ7uxT"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","\n","#x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', kernel_initializer='he_normal')(input_tensor)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","\n","x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","\n","x = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n","x = Activation('relu')(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D(pool_size=2)(x)\n","\n","x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","\n","x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling2D(pool_size=2)(x)\n","\n","# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n","x = Flatten(name='flatten')(x)\n","x = Dropout(rate=0.5)(x)\n","x = Dense(300, activation='relu', name='fc1')(x)\n","x = Dropout(rate=0.3)(x)\n","output = Dense(10, activation='softmax', name='output')(x)\n","\n","model = Model(inputs=input_tensor, outputs=output)\n","\n","model.summary()"],"metadata":{"trusted":true,"id":"tkSNDBwk7uxU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","history = model.fit(x=train_images, y=train_oh_labels, batch_size=64, epochs=30, validation_split=0.15)"],"metadata":{"trusted":true,"id":"vpGQGVAe7uxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.evaluate(test_images, test_oh_labels, batch_size=64)"],"metadata":{"trusted":true,"id":"PdP7HyHI7uxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = model.predict(np.expand_dims(test_images[0], axis=0))\n","predicted_class = np.argmax(preds, axis=1)\n","print('예측 클래스 값:', predicted_class)"],"metadata":{"trusted":true,"id":"7UkAQEUD7uxV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 학습 시 데이터를 섞는 shuffle 적용 유무에 따른  성능 테스트"],"metadata":{"id":"UnS2jpcz7uxW"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import random as python_random\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n","def set_random_seed(seed_value):\n","    np.random.seed(seed_value)\n","    python_random.seed(seed_value)\n","    tf.random.set_seed(seed_value)\n","\n","# 0 ~ 1사이값의 float32로 변경하는 함수\n","def get_preprocessed_data(images, labels):\n","    \n","    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n","    images = np.array(images/255.0, dtype=np.float32)\n","    labels = np.array(labels, dtype=np.float32)\n","    \n","    return images, labels\n","\n","# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n","def get_preprocessed_ohe(images, labels):\n","    images, labels = get_preprocessed_data(images, labels)\n","    # OHE 적용 \n","    oh_labels = to_categorical(labels)\n","    return images, oh_labels\n","\n","# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n","def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n","    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n","    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n","    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n","    \n","    # 학습 데이터를 검증 데이터 세트로 다시 분리\n","    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n","    \n","    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) "],"metadata":{"trusted":true,"id":"Y742T9LZ7uxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.datasets import cifar10\n","\n","# random seed는 2021로 고정.\n","set_random_seed(2021)\n","# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n","(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n","    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n","\n","print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"],"metadata":{"trusted":true,"id":"_LxQBDvw7uxW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### model 생성을 위한 별도 함수 생성"],"metadata":{"id":"T2WDxU7q7uxW"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","def create_model():\n","    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","\n","    #x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n","    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","    x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n","    x = Activation('relu')(x)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D(pool_size=2)(x)\n","\n","    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D(pool_size=2)(x)\n","\n","    # cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n","    x = Flatten(name='flatten')(x)\n","    x = Dropout(rate=0.5)(x)\n","    x = Dense(300, activation='relu', name='fc1')(x)\n","    x = Dropout(rate=0.3)(x)\n","    output = Dense(10, activation='softmax', name='output')(x)\n","\n","    model = Model(inputs=input_tensor, outputs=output)\n","    #model.summary()\n","    \n","    return model\n"],"metadata":{"trusted":true,"id":"aFtsH2257uxX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### shuffle을 False/True 변경하면서 테스트 "],"metadata":{"id":"A7nchRSQ7uxX"}},{"cell_type":"code","source":["model = create_model()\n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","# 먼저 shuffle을 false로 테스트 \n","noshuffle_history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=64, epochs=30, shuffle=False, \n","                    validation_data=(val_images, val_oh_labels))\n","evaluation_result = model.evaluate(test_images, test_oh_labels, batch_size=64)\n","print('#### 테스트 세트로 evaluation 결과 :', evaluation_result)\n","\n","# model이 반복적으로 메모리 차지하는것을 없애기 위해서 수행. \n","tf.keras.backend.clear_session()"],"metadata":{"_kg_hide-output":true,"trusted":true,"id":"NGE_Mi3_7uxX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### shuffle을 True로 변경하고 학습 및 테스트"],"metadata":{"id":"kb91X7E67uxY"}},{"cell_type":"code","source":["model = create_model()\n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","# shuffle을 True로 변경하여 학습 및 테스트\n","shuffle_history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=64, epochs=30, shuffle=True, \n","                    validation_data=(val_images, val_oh_labels))\n","evaluation_result = model.evaluate(test_images, test_oh_labels, batch_size=64)\n","print('#### 테스트 세트로 evaluation 결과 :', evaluation_result)\n","\n","tf.keras.backend.clear_session()"],"metadata":{"trusted":true,"id":"vEn0TlQO7uxY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 위에서 수행한 Shuffle테스트 시 validation 데이터 기반 성능 검증 시각화 "],"metadata":{"id":"hHc3UaW77uxY"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_history_shuffle(noshuffle_history, shuffle_history):\n","    figure, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n","    # shuffle과 no shuffle의 validation accuracy 비교 \n","    axs[0].plot(noshuffle_history.history['val_accuracy'], label='no shuffle acc')\n","    axs[0].plot(shuffle_history.history['val_accuracy'], label='shuffle acc')\n","    # shuffle과 no shuffle의 validation loss 비교 \n","    axs[1].plot(noshuffle_history.history['val_loss'], label='no shuffle loss')\n","    axs[1].plot(shuffle_history.history['val_loss'], label='shuffle loss')\n","    axs[0].legend()\n","    axs[1].legend()\n","\n","show_history_shuffle(noshuffle_history, shuffle_history)\n"],"metadata":{"trusted":true,"id":"AYchkcb37uxY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### batch 크기를 32, 64, 256, 512로 변경하면서 테스트"],"metadata":{"id":"b3LBw0s17uxZ"}},{"cell_type":"code","source":["b_sizes = [32, 64, 256, 512]\n","histories = []\n","evaluations = []\n","for b_size in b_sizes:\n","    model = create_model()\n","    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","    # batch_size를 순차적으로 32, 64, 256, 512로 변경하여 학습 및 evaluation 수행. \n","    print('##### batch size :', b_size, '학습 #####')\n","    history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=b_size, epochs=30, \n","                        shuffle=True, validation_data=(val_images, val_oh_labels))\n","    # batch size별 학습 history 결과 저장. \n","    histories.append(history)\n","    # 테스트 세트로 evaluation 수행하고 batch size별 결과 저장. \n","    evaluation_result = model.evaluate(test_images, test_oh_labels, batch_size=b_size)\n","    print('#### 테스트 세트로 evaluation 결과 :', evaluation_result)\n","    evaluations.append(evaluation_result)\n","    \n","    tf.keras.backend.clear_session()"],"metadata":{"trusted":true,"id":"6agtSdDM7uxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_history_batch(histories):\n","    figure, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))  \n","    # batch 크기별 validation accuracy 비교 \n","    axs[0].plot(histories[0].history['val_accuracy'], label='batch 32 acc')\n","    axs[0].plot(histories[1].history['val_accuracy'], label='batch 64 acc')\n","    axs[0].plot(histories[2].history['val_accuracy'], label='batch 256 acc')\n","    axs[0].plot(histories[3].history['val_accuracy'], label='batch 512 acc')\n","    \n","    # batch 크기별 validation loss 비교\n","    axs[1].plot(histories[0].history['val_loss'], label='batch 32 loss')\n","    axs[1].plot(histories[1].history['val_loss'], label='batch 64 loss')\n","    axs[1].plot(histories[2].history['val_loss'], label='batch 256 loss')\n","    axs[1].plot(histories[3].history['val_loss'], label='batch 512 loss')\n","    \n","    axs[0].legend()\n","    axs[1].legend()\n","\n","show_history_batch(histories)"],"metadata":{"trusted":true,"id":"FywO5v4w7uxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"trusted":true,"id":"Q0hOnDRl7uxZ"},"execution_count":null,"outputs":[]}]}