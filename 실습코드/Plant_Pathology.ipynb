{"cells":[{"metadata":{},"cell_type":"markdown","source":"### 디렉토리 구조 확인하고 학습과 테스트용 메타 정보를 DataFrame으로 생성"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\ntest_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\ntrain_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### healthy, multiple_diseases, rust, scab 컬럼이 원핫 인코딩 형식으로 되어 있음. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# healthy, multiple_diseases, rust, scab 컬럼을 합해서 sum을 만들고 sum이 1보다 큰지, 아니면 0인지 확인. \ntrain_df['sum'] = train_df['healthy'] + train_df['multiple_diseases'] + train_df['rust'] + train_df['scab']\ntrain_df[(train_df['sum'] > 1) | (train_df['sum']==0)] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 이미지의 절대 경로를 DataFrame에 추가하고, 개별 컬럼별 0/1 값을 구분하여 클래스 라벨로 생성. "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option(\"max_colwidth\", 100)\n\nIMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\ntrain_df['path'] = IMAGE_DIR + '/' + train_df['image_id'] + '.jpg'\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_label(x):\n    if x['healthy'] == 1:\n        return 'healthy'\n    elif x['multiple_diseases'] == 1:\n        return 'multiple_diseases'\n    elif x['rust'] == 1:\n        return 'rust'\n    elif x['scab'] == 1:\n        return 'scab'\n    else: return 'None'\n\n\ntrain_df['label'] = train_df.apply(lambda x:get_label(x), axis=1)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## 학습 이미지 건수 및 label별 건수\nprint('train shape:', train_df.shape)\nprint('label 별 건수')\ntrain_df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 원본 이미지 시각화\n* 녹병균 (Rust), 박테리아성 질환(scab), 복합질병(multiple_diseases), 건강(healthy)\n* 이미지 size는 (1365, 2048)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline \n\ndef show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n    for i in range(ncols):\n        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n        if augmentor is not None:\n            image = augmentor(image=image)['image']\n        axs[i].imshow(image)\n        #axs[i].axis('off')\n        axs[i].set_title(title)\n        print(image.shape)\n        \nrust_image_list = train_df[train_df['label']=='rust']['path'].iloc[:6].tolist()\nscab_image_list = train_df[train_df['label']=='scab']['path'].iloc[:6].tolist()\nhealthy_image_list = train_df[train_df['label']=='healthy']['path'].iloc[:6].tolist()\nmultiple_image_list = train_df[train_df['label']=='multiple_diseases']['path'].iloc[:6].tolist()\n\nshow_grid_images(rust_image_list, ncols=6, title='rust')\nshow_grid_images(scab_image_list, ncols=6, title='scab')\nshow_grid_images(healthy_image_list, ncols=6, title='healthy')\nshow_grid_images(multiple_image_list, ncols=6, title='multiple')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 이미지 Augmentation 적용. \n* cutout과 같은 noise는 나뭇잎의 병균 반점과 헷갈릴 수 있으므로 사용하지 않음. \n* 전체 이미지가 파란색 계열이고 병균 반점이 특정 색깔을 가지고 있으므로 색상의 변화는 적용하지 않음. \n* 전반적으로 판별하려는 나뭇잎이 전체 이미지의 중앙에 와있음. scale등의 적용 고려. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A\n\naugmentor_01 = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n    A.Blur(p=0.2)\n])\n\nshow_grid_images(rust_image_list, augmentor=None, ncols=6, title='original rust')\nshow_grid_images(rust_image_list, augmentor=augmentor_01, ncols=6, title='augmented rust')\n\nshow_grid_images(scab_image_list, augmentor=None, ncols=6, title='original scab')\nshow_grid_images(scab_image_list, augmentor=augmentor_01, ncols=6, title='augmented scab')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sequence기반의 Dataset 생성\n* 기존엔 image size가 높이와 너비가 동일하였으나, 이번엔 높이와 너비가 다를 수 있을 경우를 고려하여 image_size를 튜플로 입력\n* opencv의 resize()는 인자로 이미지 크기를 입력 받는데 가로x세로(너비x높이)의 개념으로 입력 받음. 이미지 배열의 경우는 행x열(높이x너비) 이므로 resize()호출시 이를 감안할것. \n* 캐글 컴피티션에 테스트 데이터의 결과를 submit하므로 테스트 데이트의 Label이 없음. 때문에 Dataset의 label_batch 값이 None이 될 수 있는 경우를 감안해서 코드 재수정 필요. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import Sequence\nimport sklearn \nimport cv2\n\n# 입력 인자 image_filenames, labels는 모두 numpy array로 들어옴. image size는 (높이, 너비)로 수정. \nclass Plant_Dataset(Sequence):\n    def __init__(self, image_filenames, labels, image_size=(224, 224), batch_size=64, \n                 augmentor=None, shuffle=False, pre_func=None):\n        '''\n        파라미터 설명\n        image_filenames: opencv로 image를 로드할 파일의 절대 경로들\n        labels: 해당 image의 label들\n        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n        augmentor: albumentations 객체\n        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n        '''\n        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n        self.image_filenames = image_filenames\n        self.labels = labels\n        self.image_size = image_size\n        self.batch_size = batch_size\n        self.augmentor = augmentor\n        self.pre_func = pre_func\n        # train data의 경우 \n        self.shuffle = shuffle\n        if self.shuffle:\n            # 객체 생성시에 한번 데이터를 섞음. \n            #self.on_epoch_end()\n            pass\n    \n    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n    def __len__(self):\n        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n    \n    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n    def __getitem__(self, index):\n        # index는 몇번째 batch인지를 나타냄. \n        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져오면 됨\n        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n        if self.labels is not None:\n            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n        \n        # label_batch가 None이 될 수 있음. \n        else: \n            label_batch = None\n        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n        # image_batch 배열은 float32 로 설정. \n        image_batch = np.zeros((image_name_batch.shape[0], self.image_size[0], self.image_size[1], 3), dtype='float32')\n        \n        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n        for image_index in range(image_name_batch.shape[0]):\n            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n            if self.augmentor is not None:\n                image = self.augmentor(image=image)['image']\n            #원본 이미지와 다르게 resize 적용. opencv의 resize은 (가로, 세로)의 개념임. 배열은 (높이, 너비)의 개념이므로 이에 주의하여 opencv resize 인자 입력 필요.  \n            image = cv2.resize(image, (self.image_size[1], self.image_size[0]))\n            # 만일 preprocessing_input이 pre_func인자로 들어오면 이를 이용하여 scaling 적용. \n            if self.pre_func is not None:\n                image = self.pre_func(image)\n                \n            image_batch[image_index] = image\n        \n        return image_batch, label_batch\n    \n    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n    def on_epoch_end(self):\n        if(self.shuffle):\n            #print('epoch end')\n            # 전체 image 파일의 위치와 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n        else:\n            pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 학습 데이터용 DataFrame에서 학습용/검증용 이미지 절대 경로와 Label 추출하고 이를 Dataset으로 생성. \n* 이미 학습용 DataFrame에 'healthy', 'multiple_diseases', 'rust', 'scab' 순으로 원핫 인코딩 되어 있음. \n* 캐글에서 테스트 데이터 예측한 결과를 'healthy', 'multiple_diseases', 'rust', 'scab' 순서로 제출을 요구하므로 이를 별도로 다시 원-핫 인코딩 해서는 안됨. \n* Augmentation은 앞에서 생성한 augmentor_01을 적용. pre_func는 xception용 Preprocessing 함수 적용. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\nsample_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef get_train_valid(train_df, valid_size=0.2, random_state=2021):\n    train_path = train_df['path'].values\n    # 별도의 원핫인코딩을 하지 않고  'healthy', 'multiple_diseases', 'rust', 'scab' 컬럼들을 모두 Numpy array로 변환하는 수준으로 label을 원핫 인코딩 적용. \n    train_label = train_df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n    \n    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=valid_size, random_state=random_state)\n    print('tr_path shape:', tr_path.shape, 'tr_label shape:', tr_label.shape, 'val_path shape:', val_path.shape, 'val_label shape:', val_label.shape)\n    return tr_path, val_path, tr_label, val_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n\n# image size는 224x224로 Dataset 생성. \nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 64\n\ntr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n\ntr_ds = Plant_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                          augmentor=augmentor_01, shuffle=True, pre_func=xcp_preprocess_input)\nval_ds = Plant_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                      augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n\ntr_image_batch, tr_label_batch = next(iter(tr_ds))\nval_image_batch, val_label_batch = next(iter(val_ds))\nprint(tr_image_batch.shape, val_image_batch.shape, tr_label_batch.shape, val_label_batch.shape)\nprint(tr_image_batch[0], val_image_batch[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### create_model() 함수 생성. \n* resnet50v2, xception, efficientnetb0~b7 등의 Pretrained 모델을 생성 "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential , Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\nfrom tensorflow.keras.metrics import AUC\n\nfrom tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\nfrom tensorflow.keras.applications import EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\nimport tensorflow as tf\n\n\ndef create_model(model_type='efficientnetb0', in_shape=(224, 224, 3), n_classes=4):\n    input_tensor = Input(shape=in_shape)\n\n    if model_type == 'resnet50v2':\n        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'xception':\n        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb0':\n        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb1':\n        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb2':\n        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb3':\n        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb4':\n        base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb5':\n        base_model = tf.keras.applications.EfficientNetB5(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb6':\n        base_model = tf.keras.applications.EfficientNetB6(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    elif model_type == 'efficientnetb7':\n        base_model = tf.keras.applications.EfficientNetB7(include_top=False, weights='imagenet', input_tensor=input_tensor)\n        \n    x = base_model.output  \n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)    \n    preds = Dense(units=n_classes, activation='softmax')(x)\n    model = Model(inputs=input_tensor, outputs=preds)\n    \n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### xception 모델을 생성하고 학습 수행. \n* image size는 224x224로 생성. \n* Learning Rate Scheduler는 ReduceLROnPlateau로, 초기 Learning Rate는 0.0001로 설정. \n* epochs는 10회만 설정. \n* metrics는 ROC-AUC 설정"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.metrics import AUC\n\nxcp_model_01 = create_model(model_type='xception', in_shape=(224, 224, 3))\nxcp_model_01.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=[AUC()])\n\n# 3번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\nely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n\nhistory = xcp_model_01.fit(tr_ds, epochs=10, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n               validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n               callbacks=([rlr_cb, ely_cb]), verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 테스트 데이터로 Plant의 질병을 예측하고 캐글에 제출할 submit csv 파일 만들기\n* 테스트용 DataFrame에 이미지 경로 추가. \n* 테스트용 Dataset 생성. label은 테스트 데이터에서 알 수 없으므로 None으로 입력"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\nsample_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\ntest_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\ntest_df['path'] = IMAGE_DIR + '/' + test_df['image_id'] + '.jpg'\n\ntest_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 테스트용 Dataset을 생성하고 이를 이용하여 model의 predict()를 호출하여 이미지 예측 수행. \n\ntest_path = test_df['path'].values\n# labels는 None을 입력하고 Dataset 생성. \ntest_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                        augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n#predict()로 예측 수행. \npreds = xcp_model_01.predict(test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df = pd.DataFrame(preds)\npreds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성. \npreds_df = pd.DataFrame(preds)\npreds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n# 테스트용 DataFrame에 바로 위에서 생성한 결과 DataFrame을 합친 뒤 이를 이용하여 submit용 DataFrame 생성.  \nsubmit_df = pd.concat([test_df['image_id'], preds_df], axis = 1)\nsubmit_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 캐글 제출용 CSV 생성 후 캐글에 제출 및 테스트 성능 확인  "},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df.to_csv('submit_01.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_submit_df(test_df, model):\n    test_path = test_df['path'].values\n    # labels는 None을 입력하고 Dataset 생성. \n    test_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                            augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n    #predict()로 예측 수행. \n    preds = model.predict(test_ds)\n    \n    # 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성.\n    preds_df = pd.DataFrame(preds)\n    preds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n    # 테스트용 DataFrame에 바로 위에서 생성한 결과 DataFrame을 합친 뒤 이를 이용하여 submit용 DataFrame 생성.  \n    submit_df = pd.concat([test_df['image_id'], preds_df], axis = 1)\n    \n    return submit_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = make_submit_df(test_df, xcp_model_01)\n\nsubmit_df.to_csv('submit_xcp_01.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### image 사이즈를 변경하여 재 학습 수행. \n* xception 모델을 사용하되 원본 이미지(1365, 2048)의 ratio를 어느 정도 유지하면서 변경. 이미지 사이즈를 320, 512로 변경. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n\nIMAGE_SIZE = (320, 512)\nBATCH_SIZE = 64\n\ntr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n\ntr_ds = Plant_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                          augmentor=augmentor_01, shuffle=True, pre_func=xcp_preprocess_input)\nval_ds = Plant_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n                      augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n\ntr_image_batch, tr_label_batch = next(iter(tr_ds))\nval_image_batch, val_label_batch = next(iter(val_ds))\nprint(tr_image_batch.shape, val_image_batch.shape, tr_label_batch.shape, val_label_batch.shape)\nprint(tr_image_batch[0], val_image_batch[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Config 를 이용하여 학습 수행. \n* 모델은 xception, image size는 (320, 512), \n* 초기 LR은 0.0001, LR Scheduler는 Ramp up and Step decay, \n* epochs는 10회, fine tuning을 적용하지 않음.\n* augmentor는 앞에서 설정한 augmentor_01 적용. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\nfrom tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\nimport tensorflow as tf\n\n# learning rate scheduler에 적용할 함수 선언. \ndef lrfn_01(epoch):\n    LR_START = 1e-5\n    LR_MAX = 1e-4\n    LR_RAMPUP_EPOCHS = 2\n    LR_SUSTAIN_EPOCHS = 1\n    LR_STEP_DECAY = 0.75\n    \n    def calc_fn(epoch):\n        if epoch < LR_RAMPUP_EPOCHS:\n            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n            lr = LR_MAX\n        else:\n            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n        return lr\n    \n    return calc_fn(epoch)\n\ndef lrfn_02(epoch):\n    LR_START = 1e-6\n    LR_MAX = 2e-5\n    LR_RAMPUP_EPOCHS = 2\n    LR_SUSTAIN_EPOCHS = 1\n    LR_STEP_DECAY = 0.75\n    \n    def calc_fn(epoch):\n        if epoch < LR_RAMPUP_EPOCHS:\n            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n            lr = LR_MAX\n        else:\n            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n        return lr\n    \n    return calc_fn(epoch)\n\n# Config에 입력할 callback 생성. \nlr01_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_01, verbose=1)\nlr02_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_02, verbose=1)\nrlr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n\nely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n\n# Augmentor 생성. \naugmentor_01 = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n    A.Blur(p=0.2)\n])\n\n# Config 생성. \nclass Config:\n    MODEL_TYPE = 'xception'\n    IMAGE_SIZE = (320, 512)\n    BATCH_SIZE = 32\n    N_EPOCHS = 10 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n    IS_FINE_TUNING = False\n    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n    AUGMENTOR = augmentor_01\n    PRE_FUNC = xcp_preprocess_input\n    INITIAL_LR = 0.0001\n    DEBUG = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(train_df, config=Config):\n    # 학습과 검증 데이터 이미지/레이블로 분리하고 학습/검증 Dataset 생성. \n    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n    \n    tr_ds = Plant_Dataset(tr_path, tr_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n    val_ds = Plant_Dataset(val_path, val_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n                          augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n    if config.DEBUG:\n        tr_image_batch = next(iter(tr_ds))[0]\n        val_image_batch = next(iter(val_ds))[0]\n        print(tr_image_batch.shape, val_image_batch.shape)\n        print(tr_image_batch[0], val_image_batch[0])\n        \n    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE[0], config.IMAGE_SIZE[1], 3), n_classes=4)\n    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=[AUC()])\n    \n    # 만일 Fine tuning 일 경우 아래 로직 적용. \n    if config.IS_FINE_TUNING:\n        print('####### Fine tuning 학습을 시작합니다. ########')\n        # 첫번째 Fine Tuning. Feature Extractor를 제외한 classification layer를 학습.(Feature Extractor layer들을 trainable=False 설정)\n        for layer in model.layers[:-4]:\n            layer.trainable = False\n        \n        print('####### Classification Layer들의 학습을 시작합니다. ########')\n        history = model.fit(tr_ds, epochs=config.FIRST_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n                           callbacks=(config.FIRST_CALLBACKS), verbose=1)\n        \n        # 두번째, 전체 Layer를 학습. 전체 layer를 trainable=True로 수정. 모델이 EfficientNet 계열일 경우 Batch Normalization layer는 학습 제외. \n        for layer in model.layers:\n            if config.MODEL_TYPE in 'efficientnet':\n                if not isinstance(layer, layers.BatchNormalization):\n                    layer.trainable = True\n            else:\n                layer.trainable = True\n        \n        print('####### 전체 Layer들의 학습을 시작합니다. ########')\n        history = model.fit(tr_ds, epochs=config.SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n                           callbacks=(config.SECOND_CALLBACKS), verbose=1)\n    \n    # Fine Tuning이 아닐 경우 \n    else:\n        print('####### 학습을 시작합니다. ########')\n        history = model.fit(tr_ds, epochs=config.N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n                       callbacks=(config.FIRST_CALLBACKS), verbose=1)\n        \n    return model, history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xcp_model_02, history = train_model(train_df, config=Config)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 학습된 모델을 이용하여 테스트 이미지 예측 및 결과 제출 "},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_submit_df(test_df, model, config=Config):\n    test_path = test_df['path'].values\n    # labels는 None을 입력하고 Dataset 생성. \n    test_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n                            augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n    #predict()로 예측 수행. \n    preds = model.predict(test_ds)\n    \n    # 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성.\n    preds_df = pd.DataFrame(preds)\n    preds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n    # 테스트용 DataFrame에 바로 위에서 생성한 결과 DataFrame을 합친 뒤 이를 이용하여 submit용 DataFrame 생성.  \n    submit_df = pd.concat([test_df['image_id'], preds_df], axis = 1)\n    \n    return submit_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = make_submit_df(test_df, xcp_model_02, config=Config)\n\nsubmit_df.to_csv('submit_xcp_02.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EfficientNetB3로 Pretrained 모델을 변경한 후 다시 학습 및 테스트 데이터 평가 후 제출. \n* BATCH_SIZE를 16으로 줄이지 않으면 OOM 오류 발생. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Config 생성. \nclass Config:\n    MODEL_TYPE = 'efficientnetb3'\n    IMAGE_SIZE = (320, 512)\n    BATCH_SIZE = 16\n    N_EPOCHS = 10 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n    IS_FINE_TUNING = False\n    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n    AUGMENTOR = augmentor_01\n    PRE_FUNC = eff_preprocess_input\n    INITIAL_LR = 0.0001\n    DEBUG = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"effb3_model, history = train_model(train_df, config=Config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = make_submit_df(test_df, effb3_model, config=Config)\n\nsubmit_df.to_csv('submit_effb3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EfficientNetB5로 Pretrained 모델을 변경한 후 다시 학습 및 테스트 데이터 평가 후 제출. \n* IMAGE_SIZE는 (456, 456)으로 증가.  \n* BATCH_SIZE를 8로 줄이지 않으면 OOM 오류 발생. "},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config:\n    MODEL_TYPE = 'efficientnetb5'\n    IMAGE_SIZE = (456, 456)\n    BATCH_SIZE = 8\n    N_EPOCHS = 10 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n    IS_FINE_TUNING = False\n    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n    AUGMENTOR = augmentor_01\n    PRE_FUNC = eff_preprocess_input\n    INITIAL_LR = 0.0001\n    DEBUG = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"effb5_model, history = train_model(train_df, config=Config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = make_submit_df(test_df, effb5_model, config=Config)\n\nsubmit_df.to_csv('submit_effb5.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EfficientNetB7로 Pretrained 모델을 변경한 후 다시 학습 및 테스트 데이터 평가 후 제출. \n* 기존 검증 데이터를 합쳐서 학습 데이터로 활용. \n* IMAGE_SIZE는 (456, 456)으로 유지.  \n* BATCH_SIZE를 4로 줄이지 않으면 OOM 오류 발생. "},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config:\n    MODEL_TYPE = 'efficientnetb7'\n    IMAGE_SIZE = (456, 456)\n    BATCH_SIZE = 4\n    N_EPOCHS = 15 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n    IS_FINE_TUNING = False\n    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n    AUGMENTOR = augmentor_01\n    PRE_FUNC = eff_preprocess_input\n    INITIAL_LR = 0.0001\n    DEBUG = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_only_model(train_df, config=Config):\n    # 학습과 검증 데이터 이미지/레이블로 분리하고 학습/검증 Dataset 생성. \n    train_path = train_df['path'].values\n    # 별도의 원핫인코딩을 하지 않고  'healthy', 'multiple_diseases', 'rust', 'scab' 컬럼들을 모두 Numpy array로 변환하는 수준으로 label을 원핫 인코딩 적용. \n    train_label = train_df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n    \n    tr_ds = Plant_Dataset(train_path, train_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n    if config.DEBUG:\n        tr_image_batch = next(iter(tr_ds))[0]\n        print(tr_image_batch.shape)\n        print(tr_image_batch[0])\n        \n    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE[0], config.IMAGE_SIZE[1], 3), n_classes=4)\n    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=[AUC()])\n    \n    # 만일 Fine tuning 일 경우 아래 로직 적용. \n    if config.IS_FINE_TUNING:\n        print('####### Fine tuning 학습을 시작합니다. ########')\n        # 첫번째 Fine Tuning. Feature Extractor를 제외한 classification layer를 학습.(Feature Extractor layer들을 trainable=False 설정)\n        for layer in model.layers[:-4]:\n            layer.trainable = False\n        \n        print('####### Classification Layer들의 학습을 시작합니다. ########')\n        history = model.fit(tr_ds, epochs=config.FIRST_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n                           #validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n                           callbacks=(config.FIRST_CALLBACKS), verbose=1)\n        \n        # 두번째, 전체 Layer를 학습. 전체 layer를 trainable=True로 수정. 모델이 EfficientNet 계열일 경우 Batch Normalization layer는 학습 제외. \n        for layer in model.layers:\n            if config.MODEL_TYPE in 'efficientnet':\n                if not isinstance(layer, layers.BatchNormalization):\n                    layer.trainable = True\n            else:\n                layer.trainable = True\n        \n        print('####### 전체 Layer들의 학습을 시작합니다. ########')\n        history = model.fit(tr_ds, epochs=config.SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n                           #validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n                           callbacks=(config.SECOND_CALLBACKS), verbose=1)\n    \n    # Fine Tuning이 아닐 경우 \n    else:\n        print('####### 학습을 시작합니다. ########')\n        history = model.fit(tr_ds, epochs=config.N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n                       #validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n                       callbacks=(config.FIRST_CALLBACKS), verbose=1)\n        \n    return model, history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"effb7_model, history = train_only_model(train_df, config=Config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = make_submit_df(test_df, effb7_model, config=Config)\nsubmit_df.to_csv('submit_effb7.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}